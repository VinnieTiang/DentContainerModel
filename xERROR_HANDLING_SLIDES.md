# Error Handling - Slide Preparation Material

## Dent Container Detection Pipeline

---

## ðŸ“Š Slide 1: Error Handling Overview

### Coverage Across Pipeline

âœ… **3 Main Components Protected:**

1. **UI Application** (app.py) - 5 error scenarios
2. **Model Architecture** (model_architecture.py) - 3 error scenarios
3. **Training Pipeline** (Notebook) - 3 error scenarios

### Total Error Handling Points: **11 Major Scenarios**

---

## ðŸ“Š Slide 2: UI Application - Model Loading

### Scenario: Invalid Model File

**Location:** `app.py` Lines 213-240

```python
if st.button("ðŸ”„ Load Model"):
    if model_path and os.path.exists(model_path):
        try:
            model = AttentionUNet(...)
            checkpoint = torch.load(model_path, map_location=device)
            model.load_state_dict(checkpoint)
            st.success("âœ… Model loaded successfully!")
        except Exception as e:
            st.error(f"âŒ Error loading model: {str(e)}")
            st.session_state.model_loaded = False
    else:
        st.error("âŒ Model file not found!")
```

**How it handles:**

- âœ… Pre-checks file existence
- âœ… Catches all exceptions (corrupted files, wrong architecture)
- âœ… Displays user-friendly error
- âœ… Resets state to prevent invalid operations

**Error Types:** FileNotFoundError, RuntimeError, KeyError, Corrupted files

---

## ðŸ“Š Slide 3: UI Application - File Upload Errors

### Scenario 1: Invalid Depth Map

**Location:** `app.py` Lines 418-444

```python
if uploaded_depth is not None:
    try:
        depth_map = np.load(uploaded_depth)
        st.success(f"âœ… Depth map loaded: {uploaded_depth.name}")
        st.session_state.depth_map = depth_map
    except Exception as e:
        st.error(f"âŒ Error loading depth map: {str(e)}")
        st.session_state.depth_map = None
```

### Scenario 2: Invalid RGB Image

**Location:** `app.py` Lines 447-477

```python
if uploaded_rgb is not None:
    try:
        rgb_image = Image.open(uploaded_rgb)
        rgb_array = np.array(rgb_image)
        # Handle RGBA conversion
        if rgb_array.shape[2] == 4:
            rgb_array = rgb_array[:, :, :3]
    except Exception as e:
        st.error(f"âŒ Error loading RGB image: {str(e)}")
        st.session_state.rgb_image = None
```

**How it handles:**

- âœ… Catches numpy loading errors
- âœ… Handles PIL image errors
- âœ… Clears state on failure
- âœ… Provides user guidance

---

## ðŸ“Š Slide 4: UI Application - Inference Pipeline

### Scenario: Runtime Errors During Inference

**Location:** `app.py` Lines 483-705

```python
if st.button("ðŸš€ Run Inference"):
    if not st.session_state.model_loaded:
        st.error("âŒ Please load a model first!")
    elif st.session_state.depth_map is None:
        st.error("âŒ Please upload a depth map first!")
    else:
        try:
            with st.spinner("Running inference..."):
                binary_mask, prob_mask = predict_mask(...)
                metrics = calculate_dent_metrics(...)
                # ... processing ...
        except Exception as e:
            st.error(f"âŒ Error during inference: {str(e)}")
            import traceback
            st.code(traceback.format_exc())  # Full traceback for debugging
```

**How it handles:**

- âœ… **Pre-validation:** Checks prerequisites before processing
- âœ… **Comprehensive catch:** Wraps entire inference pipeline
- âœ… **Debug info:** Shows full traceback
- âœ… **State protection:** Prevents partial state corruption

**Error Types:** CUDA OOM, model errors, metric calculation errors

---

## ðŸ“Š Slide 5: Model Architecture - Preprocessing Robustness

### Scenario: Invalid Depth Maps (NaN, Inf, Constants)

**Location:** `model_architecture.py` Lines 113-160

```python
def preprocess_depth(depth: np.ndarray) -> np.ndarray:
    depth = depth.astype(np.float32)

    # 1. Handle invalid values
    valid = np.isfinite(depth) & (depth > 0)
    if np.any(valid):
        dmin, dmax = float(depth[valid].min()), float(depth[valid].max())
        denom = dmax - dmin
        if denom < 1e-8:  # Prevent division by zero
            denom = 1e-8
        depth_n = (depth - dmin) / denom
    else:
        depth_n = np.zeros_like(depth, dtype=np.float32)  # Fallback

    # 2. Robust gradient normalization
    def robust_norm(x):
        v = x.flatten()
        v = v[np.isfinite(v)]  # Filter NaN/Inf
        if v.size == 0:
            return np.zeros_like(x, dtype=np.float32)
        med = np.median(v)  # Robust to outliers
        mad = np.median(np.abs(v - med)) + 1e-6
        out = (x - med) / (3.0 * mad)
        out = np.clip(out, -3.0, 3.0)  # Prevent extremes
        return out.astype(np.float32)
```

**How it handles:**

- âœ… **NaN/Inf filtering:** `np.isfinite()` checks
- âœ… **Division-by-zero prevention:** Multiple checks
- âœ… **Robust statistics:** Median/MAD (resistant to outliers)
- âœ… **Fallback values:** Zeros for invalid data
- âœ… **Clipping:** Prevents extreme values

---

## ðŸ“Š Slide 6: Model Architecture - Metric Validation

### Scenario: Invalid Calibration Parameters

**Location:** `model_architecture.py` Lines 245-385

```python
def calculate_dent_metrics(depth_map, dent_mask, pixel_to_cm=None, ...):
    missing_info = []
    area_valid = False

    # Validate calibration
    if pixel_to_cm is None:
        missing_info.append("pixel_to_cm conversion factor required")
    elif pixel_to_cm <= 0:
        missing_info.append("pixel_to_cm must be positive")
    elif pixel_to_cm > 10:  # Sanity check
        missing_info.append(f"pixel_to_cm ({pixel_to_cm}) seems unusually large")
        area_valid = False
    else:
        area_valid = True

    # Handle dimension mismatch
    if depth_map.shape != dent_mask.shape:
        h, w = depth_map.shape
        dent_mask = cv2.resize(dent_mask, (w, h), ...)

    # Handle empty dent regions
    if not np.any(dent_binary):
        return {'area_cm2': None, 'max_depth_mm': 0.0, ...}

    # Validate depth values
    valid_depths = dent_depths[np.isfinite(dent_depths) & (dent_depths > 0)]
    if len(valid_depths) == 0:
        return {'area_cm2': None, 'max_depth_mm': 0.0, ...}

    # Handle unknown units
    if depth_units not in depth_conversion_factors:
        missing_info.append(f"Unknown depth_units '{depth_units}'. Assuming meters.")
        conversion_factor = 1000.0  # Fallback

    # REFUSE invalid area computation
    if not area_valid:
        area_cm2 = None  # Don't compute invalid area
```

**How it handles:**

- âœ… **Parameter validation:** Checks calibration values
- âœ… **Sanity checks:** Flags unreasonable values
- âœ… **Auto-correction:** Resizes mismatched dimensions
- âœ… **Safe defaults:** Returns zeros for empty regions
- âœ… **Refusal pattern:** Sets area to None if invalid
- âœ… **Informative feedback:** Returns `missing_info` list

---

## ðŸ“Š Slide 7: Training Pipeline - Data Loading

### Scenario: Corrupted or Missing Mask Files

**Location:** Notebook Cell 5, Lines 176-177

```python
def _load_mask(self, path):
    p = Path(path)
    if p.suffix.lower() == ".npy":
        m = np.load(path)
        m = (m > 0).astype(np.uint8)
    else:
        m = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
        if m is None:
            raise RuntimeError(f"Cannot read mask: {path}")
        m = (m > 127).astype(np.uint8)
    return m
```

### Scenario: Invalid Depth Normalization

**Location:** Notebook Cell 5, `_normalize` method

```python
def _normalize(self, depth):
    valid = np.isfinite(depth) & (depth > 0)
    if not np.any(valid):
        return np.zeros_like(depth, dtype=np.float32)  # Fallback
    d = depth.copy()
    d_min = float(np.min(d[valid]))
    d_max = float(np.max(d[valid]))
    if d_max - d_min < 1e-6:  # Constant depth
        return np.zeros_like(depth, dtype=np.float32)
    norm = (d - d_min) / (d_max - d_min)
    norm[~valid] = 0.0  # Mask invalid pixels
    return norm.astype(np.float32)
```

**How it handles:**

- âœ… **File validation:** Checks if read was successful
- âœ… **Descriptive errors:** RuntimeError with file path
- âœ… **Format support:** Handles .npy and .png
- âœ… **Constant handling:** Detects and handles constant values
- âœ… **Invalid pixel masking:** Sets invalid pixels to zero

---

## ðŸ“Š Slide 8: Error Handling Strategies Summary

### 1. **Defensive Programming**

- Pre-validation of inputs
- Existence checks before operations
- Dimension validation

### 2. **Graceful Degradation**

- Optional features fail gracefully
- Fallback values for invalid data
- Continues operation when possible

### 3. **User-Friendly Messages**

- Clear error messages with emojis
- Actionable guidance
- Detailed tracebacks for debugging

### 4. **State Management**

- Clears invalid state on errors
- Prevents partial/corrupted state
- Validates prerequisites

### 5. **Robust Data Processing**

- Handles edge cases (NaN, Inf, zeros)
- Prevents division by zero
- Uses robust statistics (median, MAD)

---

## ðŸ“Š Slide 9: Error Handling Coverage Table

| Component         | Scenario            | Handling                 | Impact             |
| ----------------- | ------------------- | ------------------------ | ------------------ |
| **Model Loading** | Corrupted file      | Try-except + error msg   | âŒ Prevents crash  |
| **Model Loading** | Missing file        | Existence check          | âŒ Clear error     |
| **Depth Upload**  | Invalid .npy        | Try-except + clear state | âŒ No crash        |
| **RGB Upload**    | Corrupted image     | Try-except + optional    | âš ï¸ Continues       |
| **Inference**     | Missing prereqs     | Pre-validation           | âŒ Clear error     |
| **Inference**     | Runtime error       | Try-except + traceback   | âŒ Full details    |
| **Overlay**       | Dimension mismatch  | Auto-resize              | âœ… Auto-fix        |
| **Preprocessing** | Invalid depth       | NaN/Inf filtering        | âœ… Robust          |
| **Preprocessing** | Constant depth      | Division-by-zero check   | âœ… Fallback        |
| **Metrics**       | Invalid calibration | Validation + warnings    | âš ï¸ Refuses invalid |
| **Metrics**       | Empty regions       | Early return             | âœ… Safe            |
| **Training**      | Missing mask        | RuntimeError + path      | âŒ Stops clearly   |

**Legend:**

- âŒ **Error:** User sees error, operation stops
- âš ï¸ **Warning:** User sees warning, operation continues
- âœ… **Auto-fix:** Error handled automatically, user unaware

---

## ðŸ“Š Slide 10: Key Takeaways

### âœ… **Comprehensive Coverage**

- **11 major error scenarios** handled across pipeline
- **3 components** protected (UI, Model, Training)

### âœ… **Robust Data Processing**

- Handles **NaN, Inf, zeros, constants**
- **Division-by-zero prevention** (multiple checks)
- **Robust statistics** (median/MAD)

### âœ… **User Experience**

- **Clear error messages** with actionable guidance
- **Graceful degradation** (optional features)
- **State protection** (prevents corruption)

### âœ… **Production-Ready**

- **Pre-validation** prevents unnecessary processing
- **Informative feedback** (`missing_info` lists)
- **Debug support** (full tracebacks)

---

## ðŸ“Š Slide 11: Code Examples - Before/After

### âŒ Without Error Handling:

```python
# Dangerous - crashes on invalid input
depth_map = np.load(uploaded_depth)
model_output = model(depth_map)
```

### âœ… With Error Handling:

```python
# Safe - handles errors gracefully
if uploaded_depth is not None:
    try:
        depth_map = np.load(uploaded_depth)
        # Validate
        if not np.any(np.isfinite(depth_map)):
            st.error("Invalid depth map: all NaN/Inf")
            return
        model_output = model(depth_map)
    except Exception as e:
        st.error(f"Error: {str(e)}")
        st.session_state.depth_map = None
```

**Benefits:**

- âœ… No crashes
- âœ… Clear user feedback
- âœ… State protection
- âœ… Graceful failure

---

## ðŸ“Š Slide 12: Error Handling Metrics

### Coverage Statistics:

- **Model Loading:** 100% coverage (2 scenarios)
- **File Upload:** 100% coverage (2 scenarios)
- **Inference Pipeline:** 100% coverage (1 scenario)
- **Preprocessing:** 100% coverage (3 edge cases)
- **Metrics:** 100% coverage (3 validation checks)
- **Training:** 100% coverage (3 scenarios)

### Error Types Handled:

- âœ… File I/O errors (missing, corrupted)
- âœ… Data validation errors (NaN, Inf, invalid shapes)
- âœ… Runtime errors (CUDA OOM, model errors)
- âœ… Parameter validation (calibration, thresholds)
- âœ… Edge cases (empty data, constants, zeros)

### Result:

**ðŸ›¡ï¸ Production-ready error handling across entire pipeline**





